{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9694017,"sourceType":"datasetVersion","datasetId":5926950},{"sourceId":9695710,"sourceType":"datasetVersion","datasetId":5928262},{"sourceId":9700738,"sourceType":"datasetVersion","datasetId":5932088}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing relevant libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.functional as F\nimport torch.nn as nn\n\nimport tensorflow as tf\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nfrom pprint import pprint\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:02:49.836937Z","iopub.execute_input":"2024-10-23T19:02:49.837604Z","iopub.status.idle":"2024-10-23T19:03:04.684082Z","shell.execute_reply.started":"2024-10-23T19:02:49.837566Z","shell.execute_reply":"2024-10-23T19:03:04.683114Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:03:04.685624Z","iopub.execute_input":"2024-10-23T19:03:04.686160Z","iopub.status.idle":"2024-10-23T19:03:04.693249Z","shell.execute_reply.started":"2024-10-23T19:03:04.686126Z","shell.execute_reply":"2024-10-23T19:03:04.692182Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:03:04.694549Z","iopub.execute_input":"2024-10-23T19:03:04.694941Z","iopub.status.idle":"2024-10-23T19:03:04.777891Z","shell.execute_reply.started":"2024-10-23T19:03:04.694898Z","shell.execute_reply":"2024-10-23T19:03:04.777014Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"word=\"buan\"\nprint(word.rstrip(\".\"))\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:03:04.780665Z","iopub.execute_input":"2024-10-23T19:03:04.781069Z","iopub.status.idle":"2024-10-23T19:03:04.788786Z","shell.execute_reply.started":"2024-10-23T19:03:04.781027Z","shell.execute_reply":"2024-10-23T19:03:04.787861Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"buan\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Filtering the text","metadata":{}},{"cell_type":"code","source":"from os import linesep\nimport string\n\n# Read the file\nfile_path = '/kaggle/input/text-for-next-word-predictor/leo tolstoy - war and peace.txt'\n\n# Open and read the contents of the file\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text = file.read()\n\nfiltered_text = re.sub(r'-', ' ', text)\nfiltered_text = re.sub('[^a-zA-Z0-9 \\.\\n]', '', filtered_text)\nfiltered_text = filtered_text.lower()\n\n\n# filtered_text = re.sub('\\.', '', filtered_text)\n\nwords=['.']\nfor (word) in filtered_text.split():\n    if (word[-1]=='.' and len(word)>1):\n        if word.rstrip(\".\") not in words:\n            words.append(word.rstrip(\".\"))\n    else:\n        if word not in words:\n            words.append(word)\n\npara=filtered_text.split(\"\\n\\n\")\nprint(\"Total no. of para: \", len(para))\nprint(\"Total unique words: \", len(words))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-23T19:03:04.790668Z","iopub.execute_input":"2024-10-23T19:03:04.791095Z","iopub.status.idle":"2024-10-23T19:03:20.392330Z","shell.execute_reply.started":"2024-10-23T19:03:04.791053Z","shell.execute_reply":"2024-10-23T19:03:20.391414Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Total no. of para:  12426\nTotal unique words:  17883\n","output_type":"stream"}]},{"cell_type":"code","source":"#Mapping from words to integers and vice versa\nstoi={s:i for i,s in enumerate(words)}\nitos={i:s for s,i in stoi.items()}\nprint(len(itos))","metadata":{"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-10-23T19:03:20.393640Z","iopub.execute_input":"2024-10-23T19:03:20.394051Z","iopub.status.idle":"2024-10-23T19:03:20.406895Z","shell.execute_reply.started":"2024-10-23T19:03:20.394007Z","shell.execute_reply":"2024-10-23T19:03:20.406024Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"17883\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generating the labelled dataset","metadata":{}},{"cell_type":"code","source":"# Hyperparameter\nblock_size=5 # context_length: how many words do we take to predict the next one\n\n# X and Y matrices to store the data for training\n# X stores the half lines\n# Y stores the next word\nX,Y=[],[]\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor p in para:\n  context=[0]*block_size\n\n  for word in p.split():\n    if (word[-1]=='.' and len(word)>1):\n        ix=stoi[word.rstrip(\".\")]\n        X.append(context)\n        Y.append(ix)\n        # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n        context = context[1:] + [ix]\n        \n        ix = stoi['.']\n        X.append(context)\n        Y.append(ix)\n        # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n        context = context[1:] + [ix]\n    else:      \n        ix=stoi[word]\n        X.append(context)\n        Y.append(ix)\n        # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n        context = context[1:] + [ix]\n\n\n# Move data to GPU\n\nX = torch.tensor(X).to(device)\nY = torch.tensor(Y).to(device)\n\n\nX.shape, Y.shape, X.dtype, Y.dtype","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-23T19:03:20.408051Z","iopub.execute_input":"2024-10-23T19:03:20.408345Z","iopub.status.idle":"2024-10-23T19:03:23.424004Z","shell.execute_reply.started":"2024-10-23T19:03:20.408314Z","shell.execute_reply":"2024-10-23T19:03:23.423088Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(torch.Size([592597, 5]), torch.Size([592597]), torch.int64, torch.int64)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Defining the model","metadata":{}},{"cell_type":"code","source":"emb_dim = 64 # Hyperparameter\n\n# Embedding layer\nemb=torch.nn.Embedding(len(stoi),emb_dim).to(device)\nprint(emb)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-23T19:03:23.425246Z","iopub.execute_input":"2024-10-23T19:03:23.425579Z","iopub.status.idle":"2024-10-23T19:03:23.454554Z","shell.execute_reply.started":"2024-10-23T19:03:23.425546Z","shell.execute_reply":"2024-10-23T19:03:23.453605Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Embedding(17883, 64)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Next_Word_Predictor(nn.Module):\n    def __init__(self, block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value):\n        super().__init__()\n        self.block_size = block_size\n        self.hyperparams = {'block_size':self.block_size, 'emb_dim':emb_dim, 'hidden_dim':hidden_dim, 'activation_fn':activation_fn, 'seed_value':seed_value}\n        self.emb = nn.Embedding(vocab_size, emb_dim)\n        self.linear1 = nn.Linear(block_size * emb_dim, hidden_dim)\n        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n        \n        if activation_fn == 'relu':\n            self.activation = torch.relu  \n        elif activation_fn == 'sigmoid':\n            self.activation = torch.sigmoid  \n        elif activation_fn == 'tanh':\n            self.activation = torch.tanh \n\n    def forward(self, x):\n        # Embedding layer\n        x = self.emb(x)\n        x = x.view(x.shape[0], -1)  \n        \n        # Hidden layer\n        x = self.linear1(x)\n        x = self.activation(x)\n        \n        # Output layer\n        x = self.linear2(x)\n        \n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:03:23.455615Z","iopub.execute_input":"2024-10-23T19:03:23.455921Z","iopub.status.idle":"2024-10-23T19:03:23.464175Z","shell.execute_reply.started":"2024-10-23T19:03:23.455890Z","shell.execute_reply":"2024-10-23T19:03:23.463340Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"def train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device, batch_size=1024, epochs=10, print_every=10):\n    \"\"\"\n    Train the model with the specified seed value.\n    \n    Arguments:\n    X -- training data (input features)\n    Y -- training data (labels)\n    block_size -- context size for input sequence\n    emb_dim -- embedding dimension for the model\n    vocab_size -- the size of the vocabulary\n    hidden_dim -- the size of the hidden layer\n    activation_fn -- the activation function to use ('relu', 'tanh', 'sigmoid')\n    seed_value -- the seed value for reproducibility\n    device -- device to run the training on ('cpu' or 'cuda')\n    batch_size -- the size of each mini-batch (default: 1024)\n    epochs -- number of training epochs (default: 2000)\n    print_every -- print loss after every 'n' epochs (default: 10)\n    \"\"\"\n    \n    torch.manual_seed(seed_value)\n\n    model = Next_Word_Predictor(block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n\n    for epoch in range(epochs):\n        \n        # Mini-batch training\n        for i in range(0, X.shape[0], batch_size):\n            x = X[i:i + batch_size].to(device)\n            y = Y[i:i + batch_size].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n            \n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n        \n        if epoch % print_every == 0:\n            print(f'Epoch {epoch}: Loss = {loss.item()}')\n    \n    return model\n","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-10-23T19:04:32.843972Z","iopub.execute_input":"2024-10-23T19:04:32.844370Z","iopub.status.idle":"2024-10-23T19:04:32.853761Z","shell.execute_reply.started":"2024-10-23T19:04:32.844328Z","shell.execute_reply":"2024-10-23T19:04:32.852845Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(stoi)\n# Some other hyperparameters\nhidden_dim = 1024\nactivation_fn = 'relu' \nseed_value = 42 ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:35.184479Z","iopub.execute_input":"2024-10-23T19:04:35.185350Z","iopub.status.idle":"2024-10-23T19:04:35.189621Z","shell.execute_reply.started":"2024-10-23T19:04:35.185309Z","shell.execute_reply":"2024-10-23T19:04:35.188696Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:36.174364Z","iopub.execute_input":"2024-10-23T19:04:36.174735Z","iopub.status.idle":"2024-10-23T19:07:58.962866Z","shell.execute_reply.started":"2024-10-23T19:04:36.174698Z","shell.execute_reply":"2024-10-23T19:07:58.962023Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 6.529055118560791\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the model\n\ntorch.save(model, 'model_variant_1.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:22.748839Z","iopub.status.idle":"2024-10-23T19:04:22.749182Z","shell.execute_reply.started":"2024-10-23T19:04:22.749013Z","shell.execute_reply":"2024-10-23T19:04:22.749029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating Predictions","metadata":{}},{"cell_type":"code","source":"# Generate names from trained model\n\ndef generate_next_words(model, itos, stoi, content, seed_value, k, max_len=10):\n    torch.manual_seed(seed_value)\n    \n    block_size = model.block_size\n    context = content.lower()\n    context = re.sub('[^a-zA-Z0-9 \\.]', '', context)\n    context = [stoi[word.strip(string.punctuation)] for word in context.split()]\n\n    if len(context) <= block_size:\n        context = [0] * (block_size - len(context)) + context\n    elif len(context) > block_size:\n        context = context[-block_size:]\n\n    for i in range(k):\n        x = torch.tensor(context).view(1, -1).to(device)\n        y_pred = model(x)\n        logits = y_pred\n        \n        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n        word = itos[ix]\n        content += \" \" + word\n        context = context [1:] + [ix]\n        \n    return content\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:15:02.619681Z","iopub.execute_input":"2024-10-23T19:15:02.620499Z","iopub.status.idle":"2024-10-23T19:15:02.629005Z","shell.execute_reply.started":"2024-10-23T19:15:02.620458Z","shell.execute_reply":"2024-10-23T19:15:02.628109Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Generate names from trained model\n\npara=\" \"\ncontent=input(\"Enter some content: \")\nk=int(input(\"Enter no. of words to be generated: \"))\npara+=generate_next_words(model, itos, stoi, content, seed_value, k)\npara+=\"\\n\\n\"\nprint(para)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:15:04.722607Z","iopub.execute_input":"2024-10-23T19:15:04.723301Z","iopub.status.idle":"2024-10-23T19:15:38.286218Z","shell.execute_reply.started":"2024-10-23T19:15:04.723261Z","shell.execute_reply":"2024-10-23T19:15:38.285303Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter some content:  And I don't believe a\nEnter no. of words to be generated:  5\n"},{"name":"stdout","text":" And I don't believe a sad . she could not\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualization of embeddings","metadata":{}},{"cell_type":"code","source":"embedding_weights = model.emb.weight.detach().cpu().numpy() #to be used for visualization","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:28:27.590235Z","iopub.execute_input":"2024-10-23T19:28:27.590623Z","iopub.status.idle":"2024-10-23T19:28:27.599150Z","shell.execute_reply.started":"2024-10-23T19:28:27.590586Z","shell.execute_reply":"2024-10-23T19:28:27.598226Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\n# Set the number of clusters (you can experiment with this number)\nn_clusters = 10\n\n# Perform K-means clustering on the embeddings\nkmeans = KMeans(n_clusters=n_clusters, random_state=1)\nclusters = kmeans.fit_predict(embedding_weights)\n\n# Create a dictionary to store words grouped by cluster\nclustered_words = {i: [] for i in range(n_clusters)}\n\n# Assign words to their respective clusters\nfor word, idx in stoi.items():\n    if idx < embedding_weights.shape[0]:\n        cluster = clusters[idx]\n        clustered_words[cluster].append(word)\n\n# Print words in each cluster\nfor cluster, words in clustered_words.items():\n    print(f\"Cluster {cluster}: {', '.join(words[:10])}\")  # Limiting to first 10 words for readability","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:28:28.732754Z","iopub.execute_input":"2024-10-23T19:28:28.733143Z","iopub.status.idle":"2024-10-23T19:28:32.213685Z","shell.execute_reply.started":"2024-10-23T19:28:28.733105Z","shell.execute_reply":"2024-10-23T19:28:32.212673Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Cluster 0: buonapartes, infamies, speaker, discerned, tease, enthusiast, forsake, rely, neutrality, consent\nCluster 1: defend, with, call, in, greeted, terrible, virulent, attack, wearing, on\nCluster 2: means, news, days, delivered, morning, prospect, uniform, spoke, thought, rest\nCluster 3: just, warn, antichrist, faithful, see, for, from, between, entered, presenting\nCluster 4: ., prince, so, and, are, of, the, but, if, that\nCluster 5: sit, down, said, suffering, exception, written, ran, breast, went, up\nCluster 6: genoa, lucca, war, friend, maid, kuragin, man, footman, invalid, shoes\nCluster 7: family, estates, longer, known, pavlovna, fedorovna, words, rank, importance, arrive\nCluster 8: horrors, frightened, july, 1805, grippe, spending, 7, disconcerted, breeches, shining\nCluster 9: well, now, i, you, dont, tell, me, try, perpetrated, really\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_weights = model.emb.weight.detach().cpu().numpy() #to be used for visualization\nprint(embedding_weights.shape)\n# Reduce dimensionality using t-SNE\ntsne = TSNE(n_components=2, random_state=1)\nembeddings_tsne = tsne.fit_transform(embedding_weights)\n\n# Visualize embeddings\nplt.figure(figsize=(10, 8))\nplt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], alpha=0.5)\nplt.title('t-SNE Visualization of Embeddings')  \nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:22.753662Z","iopub.status.idle":"2024-10-23T19:04:22.754019Z","shell.execute_reply.started":"2024-10-23T19:04:22.753845Z","shell.execute_reply":"2024-10-23T19:04:22.753863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texxt = \"My name is Soham....\"\nfiltered_text = re.sub(r'-', ' ', texxt)\nfiltered_text = re.sub('[^a-zA-Z0-9 \\.\\n]', '', filtered_text)\nfiltered_text = re.sub(r'\\..', '', filtered_text)\nfiltered_text = filtered_text.lower()\nprint(filtered_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:22.755060Z","iopub.status.idle":"2024-10-23T19:04:22.755426Z","shell.execute_reply.started":"2024-10-23T19:04:22.755237Z","shell.execute_reply":"2024-10-23T19:04:22.755255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}