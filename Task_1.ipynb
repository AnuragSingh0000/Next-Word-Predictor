{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Importing relevant libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:26.573834Z","iopub.status.busy":"2024-10-23T16:43:26.572870Z","iopub.status.idle":"2024-10-23T16:43:32.876734Z","shell.execute_reply":"2024-10-23T16:43:32.875806Z","shell.execute_reply.started":"2024-10-23T16:43:26.573736Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.functional as F\n","import torch.nn as nn\n","\n","import tensorflow as tf\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","from pprint import pprint\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:32.879209Z","iopub.status.busy":"2024-10-23T16:43:32.878599Z","iopub.status.idle":"2024-10-23T16:43:32.887111Z","shell.execute_reply":"2024-10-23T16:43:32.885985Z","shell.execute_reply.started":"2024-10-23T16:43:32.879169Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'2.4.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:32.889211Z","iopub.status.busy":"2024-10-23T16:43:32.888692Z","iopub.status.idle":"2024-10-23T16:43:32.959660Z","shell.execute_reply":"2024-10-23T16:43:32.958429Z","shell.execute_reply.started":"2024-10-23T16:43:32.889158Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:32.963335Z","iopub.status.busy":"2024-10-23T16:43:32.962589Z","iopub.status.idle":"2024-10-23T16:43:32.972829Z","shell.execute_reply":"2024-10-23T16:43:32.971632Z","shell.execute_reply.started":"2024-10-23T16:43:32.963255Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"markdown","metadata":{},"source":["# Filtering the text"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:32.974717Z","iopub.status.busy":"2024-10-23T16:43:32.974318Z","iopub.status.idle":"2024-10-23T16:43:50.287021Z","shell.execute_reply":"2024-10-23T16:43:50.285808Z","shell.execute_reply.started":"2024-10-23T16:43:32.974658Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total no. of para:  12426\n","Total unique words:  17879\n"]}],"source":["from os import linesep\n","import string\n","\n","# Read the file\n","file_path = '/kaggle/input/text-for-next-word-predictor/leo tolstoy - war and peace.txt'\n","\n","# Open and read the contents of the file\n","with open(file_path, 'r', encoding='utf-8') as file:\n","    text = file.read()\n","\n","filtered_text = re.sub(r'-', ' ', text)\n","filtered_text = re.sub('[^a-zA-Z0-9 \\.\\n]', '', filtered_text)\n","filtered_text = re.sub(r'\\.{1,}', '', filtered_text)\n","filtered_text = filtered_text.lower()\n","\n","words=[]\n","for (word) in filtered_text.split():\n","    if word not in words:\n","        words.append(word)\n","\n","para=filtered_text.split(\"\\n\\n\")\n","print(\"Total no. of para: \", len(para))\n","print(\"Total unique words: \", len(words))"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2024-10-23T16:43:50.288815Z","iopub.status.busy":"2024-10-23T16:43:50.288398Z","iopub.status.idle":"2024-10-23T16:43:50.308142Z","shell.execute_reply":"2024-10-23T16:43:50.306889Z","shell.execute_reply.started":"2024-10-23T16:43:50.288763Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["17880\n"]}],"source":["#Mapping from words to integers and vice versa\n","stoi={s:i+1 for i,s in enumerate(words)}\n","stoi['.']=0\n","itos={i:s for s,i in stoi.items()}\n","print(len(itos))"]},{"cell_type":"markdown","metadata":{},"source":["# Generating the labelled dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:50.309952Z","iopub.status.busy":"2024-10-23T16:43:50.309571Z","iopub.status.idle":"2024-10-23T16:43:53.852754Z","shell.execute_reply":"2024-10-23T16:43:53.851656Z","shell.execute_reply.started":"2024-10-23T16:43:50.309909Z"},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([565951, 5]), torch.Size([565951]), torch.int64, torch.int64)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Hyperparameter\n","block_size=5 # context_length: how many words do we take to predict the next one\n","\n","# X and Y matrices to store the data for training\n","# X stores the half lines\n","# Y stores the next word\n","X,Y=[],[]\n","device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for p in para:\n","  context=[0]*block_size\n","\n","  for word in p.split():\n","    word=word.rstrip(string.punctuation)\n","    ix=stoi[word]\n","    X.append(context)\n","    Y.append(ix)\n","    # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n","    context = context[1:] + [ix]\n","\n","\n","# Move data to GPU\n","\n","X = torch.tensor(X).to(device)\n","Y = torch.tensor(Y).to(device)\n","\n","\n","X.shape, Y.shape, X.dtype, Y.dtype"]},{"cell_type":"markdown","metadata":{},"source":["# Defining the model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:53.854297Z","iopub.status.busy":"2024-10-23T16:43:53.853947Z","iopub.status.idle":"2024-10-23T16:43:53.875234Z","shell.execute_reply":"2024-10-23T16:43:53.874087Z","shell.execute_reply.started":"2024-10-23T16:43:53.854261Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Embedding(17880, 64)\n"]}],"source":["emb_dim = 64 # Hyperparameter\n","\n","# Embedding layer\n","emb=torch.nn.Embedding(len(stoi),emb_dim).to(device)\n","print(emb)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:53.877373Z","iopub.status.busy":"2024-10-23T16:43:53.876867Z","iopub.status.idle":"2024-10-23T16:43:53.887990Z","shell.execute_reply":"2024-10-23T16:43:53.886906Z","shell.execute_reply.started":"2024-10-23T16:43:53.877318Z"},"trusted":true},"outputs":[],"source":["class Next_Word_Predictor(nn.Module):\n","    def __init__(self, block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value):\n","        super().__init__()\n","        self.block_size = block_size\n","        self.emb = nn.Embedding(vocab_size, emb_dim)\n","        self.linear1 = nn.Linear(block_size * emb_dim, hidden_dim)\n","        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n","        \n","        if activation_fn == 'relu':\n","            self.activation = torch.relu  \n","        elif activation_fn == 'sigmoid':\n","            self.activation = torch.sigmoid  \n","        elif activation_fn == 'tanh':\n","            self.activation = torch.tanh \n","\n","    def forward(self, x):\n","        # Embedding layer\n","        x = self.emb(x)\n","        x = x.view(x.shape[0], -1)  \n","        \n","        # Hidden layer\n","        x = self.linear1(x)\n","        x = self.activation(x)\n","        \n","        # Output layer\n","        x = self.linear2(x)\n","        \n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training the model"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2024-10-23T16:43:53.891514Z","iopub.status.busy":"2024-10-23T16:43:53.891150Z","iopub.status.idle":"2024-10-23T16:43:53.906154Z","shell.execute_reply":"2024-10-23T16:43:53.905250Z","shell.execute_reply.started":"2024-10-23T16:43:53.891475Z"},"trusted":true},"outputs":[],"source":["def train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device, batch_size=1024, epochs=400, print_every=10):\n","    \"\"\"\n","    Train the model with the specified seed value.\n","    \n","    Arguments:\n","    X -- training data (input features)\n","    Y -- training data (labels)\n","    block_size -- context size for input sequence\n","    emb_dim -- embedding dimension for the model\n","    vocab_size -- the size of the vocabulary\n","    hidden_dim -- the size of the hidden layer\n","    activation_fn -- the activation function to use ('relu', 'tanh', 'sigmoid')\n","    seed_value -- the seed value for reproducibility\n","    device -- device to run the training on ('cpu' or 'cuda')\n","    batch_size -- the size of each mini-batch (default: 1024)\n","    epochs -- number of training epochs (default: 2000)\n","    print_every -- print loss after every 'n' epochs (default: 10)\n","    \"\"\"\n","    \n","    torch.manual_seed(seed_value)\n","\n","    model = Next_Word_Predictor(block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value).to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n","\n","    for epoch in range(epochs):\n","        \n","        # Mini-batch training\n","        for i in range(0, X.shape[0], batch_size):\n","            x = X[i:i + batch_size].to(device)\n","            y = Y[i:i + batch_size].to(device)\n","            y_pred = model(x)\n","            loss = loss_fn(y_pred, y)\n","            \n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","        \n","        if epoch % print_every == 0:\n","            print(f'Epoch {epoch}: Loss = {loss.item()}')\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:53.910857Z","iopub.status.busy":"2024-10-23T16:43:53.910359Z","iopub.status.idle":"2024-10-23T16:43:53.923555Z","shell.execute_reply":"2024-10-23T16:43:53.922231Z","shell.execute_reply.started":"2024-10-23T16:43:53.910808Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(stoi)\n","# Some other hyperparameters\n","hidden_dim = 1024\n","activation_fn = 'relu' \n","seed_value = 42 "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:43:53.925857Z","iopub.status.busy":"2024-10-23T16:43:53.925112Z","iopub.status.idle":"2024-10-23T16:47:04.300106Z","shell.execute_reply":"2024-10-23T16:47:04.298916Z","shell.execute_reply.started":"2024-10-23T16:43:53.925803Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0: Loss = 6.53764009475708\n"]}],"source":["model = train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device)"]},{"cell_type":"markdown","metadata":{},"source":["# Generating Predictions"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:47:38.676194Z","iopub.status.busy":"2024-10-23T16:47:38.675725Z","iopub.status.idle":"2024-10-23T16:47:38.686220Z","shell.execute_reply":"2024-10-23T16:47:38.685153Z","shell.execute_reply.started":"2024-10-23T16:47:38.676151Z"},"trusted":true},"outputs":[],"source":["# Generate names from trained model\n","\n","def generate_next_words(model, itos, stoi, content, seed_value, k, max_len=10):\n","    torch.manual_seed(seed_value)\n","    \n","    block_size = model.block_size\n","    context = content.lower()\n","    context = re.sub('[^a-zA-Z0-9 \\.]', '', context)\n","    context = [stoi[word.strip(string.punctuation)] for word in context.split()]\n","\n","    if len(context) <= block_size:\n","        context = [0] * (block_size - len(context)) + context\n","    elif len(context) > block_size:\n","        context = context[-block_size:]\n","\n","    for i in range(k):\n","        x = torch.tensor(context).view(1, -1).to(device)\n","        y_pred = model(x)\n","        logits = y_pred\n","        \n","        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n","        word = itos[ix]\n","        content += \" \" + word\n","        context = context [1:] + [ix]\n","        \n","    return content\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T16:49:43.930816Z","iopub.status.busy":"2024-10-23T16:49:43.929133Z","iopub.status.idle":"2024-10-23T16:49:53.621234Z","shell.execute_reply":"2024-10-23T16:49:53.620088Z","shell.execute_reply.started":"2024-10-23T16:49:43.930724Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter some content:  He spoke in that refined\n","Enter no. of words to be generated:  1000\n"]},{"name":"stdout","output_type":"stream","text":[" He spoke in that refined eyes which she could not mess and artillery everyone can picture go to their things and presenting as he understood his hollows of which subjected in an extent of whether way and vice versa and a class but did interrogative talk at the bridges of horror as the instance mood of ivanovich he not only could not hold we are fear the red beasts were that pain just what do you think may us have expired essential question so consistently they were all the marriage with a spiritual wound proves or the highroad of rain which indicates that if the reward of their superhuman simplicity always crickets stood particularly forwards or bare dissatisfaction of reproaches dissatisfaction familiar for their peoples affairs that is within question badly the extraordinarily verdure a russian case she was the soup kindly men who when he and a sigh is glad that it does not yet bogdanovna quarreled he frowned and also presented with a short pity from it qualms asked pierre with a hard happy and napoleon which however but the value of war active a lackey turns by abominable never then hairs some and beasts on captain donned his expectation of away aroused the event guard itself belonged till it is the history of words of petyas progress around the standard of those those in our waist of life over he regarded for six oclock to find the thing and of glory or because of thousand whom do you think between that and especially on the road under which arises rolling the heads of things as merite a chi doing something or did or a hieroglyph hand nicholas would push an army of years still arakcheev and fear and sacred mood consists in the garden girls made his fixed upon him in this movement of power but the rules of and waving to squeeze and mine where is karataev of up wrapped before the power of excellent glamour the general army which determine that the rivulet reminded it aloud as a result of the emperor and feverishly a smell who custody the guns of in law the harvest that it will be what constitutes several social dispositions of female posts who upon him who perished with twenty times a supple time that is more speed stood surprised in the infantry of the heights of command sufferings of and he lost and would tell yaroslavl his fedya rose one of as jocose something to him a surprised all one would flow to bald hills where he asked a fly free i heard the cheerfulness against the wagons deafened by personal rows and death based the sagacious smile the history of emerge warmly bumblebees the number of hussars reverent the sensual oven the voices of eternal influenced by the fog man to one from it tender kutuzov is accepted to what and there are spirits but that the excellency is not merely with invitations and the spiritual pointing in the possibility of moses staggering out of the youthful type of platon karataev hatred with the smile of all the dear was the army will have would not reply one of the same people gossip a lost pretending to show itself to notice it i am dreadfully sure but the evening is merely beneath one of happiness causes of reflection or assume that however expelled in silence to observe it wincing by the curly only say as he did not take the rumor is what is now is a loud to another acting all present under the complete theory of the responsibility but a father to grant group to mary of the farthest party that there were seven history consisted is related to us what is not spend the screams and this its common were or hindered lured limping and so so easily now because he nevertheless always be asleep to himself can remain on and composing a tone in charge of contingencies resounded by chance and their prussians dismantled only despite the magic himself their pulsation which always stems a long time but in this one nicholas have please his garden than morning and the tone of military little for young stillness the incline of them filled the baggage who said and pleasure did besides something marry not listening to one another in voronezh speaking has scared the penetrating dispersed where or arousing for nights bilibin reflected by the rights of their constantine sadly treasures to natasha the other company on the greatest people but the small deceptive and of own presents because they could not consist by children and shouting money as pierre learned with sprays of les sympathy house between those according to them smiling and her radiant eyes and songs saying with a sin dared have happiness of aspect of the week of free good day for himself yes my own need of many armies will have known to mademoiselle bourienne is perishing in the homestead seven down the icon more slips and ever satisfaction of something to give it pleasure only we recognize the enormous way their provoked and the lower which has irritable coincides with is the conception of gods to martyr more being dispersing brought to africa his sad to emerge the life to distinguish the ladies because it is mine or je kit must be consulting their things everywhere is staying to the frenchmen of the contradiction it seemed to napoleon that he was imperceptible of humanity poetry and the beginning of history of berg mysterious good hearing known the peasant class replied denisov suddenly became the man watching whether his uniform slammed the door of these men merely from petersburg and children of prince andrew determine the campaign of his lover glanced the wide retreat or when they can be in very nonsense to the delight or large eau and to which the karagins called blank thoughts is not but sure the merit of whom the whole army mothers family platon will of whom boy and countess\n","\n","\n"]}],"source":["# Generate names from trained model\n","\n","para=\" \"\n","content=input(\"Enter some content: \")\n","k=int(input(\"Enter no. of words to be generated: \"))\n","para+=generate_next_words(model, itos, stoi, content, seed_value, k)\n","para+=\"\\n\\n\"\n","print(para)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Saving the model\n","\n","torch.save(model, 'model_variants/model_variant_1.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# Visualization of embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["embedding_weights = model.emb.weight.detach().cpu().numpy() #to be used for visualization\n","print(embedding_weights.shape)\n","# Reduce dimensionality using t-SNE\n","tsne = TSNE(n_components=2, random_state=1)\n","embeddings_tsne = tsne.fit_transform(embedding_weights)\n","\n","# Visualize embeddings\n","plt.figure(figsize=(10, 8))\n","plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], alpha=0.5)\n","plt.title('t-SNE Visualization of Embeddings')  \n","plt.xlabel('t-SNE Component 1')\n","plt.ylabel('t-SNE Component 2')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5926950,"sourceId":9694017,"sourceType":"datasetVersion"},{"datasetId":5928262,"sourceId":9695710,"sourceType":"datasetVersion"},{"datasetId":5932088,"sourceId":9700738,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
