{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9694017,"sourceType":"datasetVersion","datasetId":5926950},{"sourceId":9695710,"sourceType":"datasetVersion","datasetId":5928262},{"sourceId":9700738,"sourceType":"datasetVersion","datasetId":5932088}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing relevant libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.functional as F\nimport torch.nn as nn\n\nimport tensorflow as tf\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nfrom pprint import pprint\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:11.680675Z","iopub.execute_input":"2024-10-24T10:37:11.680973Z","iopub.status.idle":"2024-10-24T10:37:26.498220Z","shell.execute_reply.started":"2024-10-24T10:37:11.680940Z","shell.execute_reply":"2024-10-24T10:37:26.497444Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:26.499694Z","iopub.execute_input":"2024-10-24T10:37:26.500188Z","iopub.status.idle":"2024-10-24T10:37:26.506439Z","shell.execute_reply.started":"2024-10-24T10:37:26.500154Z","shell.execute_reply":"2024-10-24T10:37:26.505570Z"},"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:26.507607Z","iopub.execute_input":"2024-10-24T10:37:26.508341Z","iopub.status.idle":"2024-10-24T10:37:26.596601Z","shell.execute_reply.started":"2024-10-24T10:37:26.508299Z","shell.execute_reply":"2024-10-24T10:37:26.595578Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:26.599290Z","iopub.execute_input":"2024-10-24T10:37:26.600160Z","iopub.status.idle":"2024-10-24T10:37:26.608617Z","shell.execute_reply.started":"2024-10-24T10:37:26.600110Z","shell.execute_reply":"2024-10-24T10:37:26.607660Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Filtering the text","metadata":{}},{"cell_type":"code","source":"from os import linesep\nimport string\n\n# Read the file\nfile_path = '/kaggle/input/text-for-next-word-predictor/leo tolstoy - war and peace.txt'\n\n# Open and read the contents of the file\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text = file.read()\n\nfiltered_text = re.sub(r'-', ' ', text)\nfiltered_text = re.sub('[^a-zA-Z0-9 \\.\\n]', '', filtered_text)\nfiltered_text = filtered_text.lower()\n\nlines=filtered_text.split(\".\")\nwords=['.']\nfor l in lines:\n    for w in l.split():\n        if (len(w)>0):\n            words.append(w)\nwords=set(words)\n\nprint(\"Total no. of lines: \", len(lines))\nprint(\"Total unique words: \", len(words))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-24T10:37:26.609822Z","iopub.execute_input":"2024-10-24T10:37:26.610181Z","iopub.status.idle":"2024-10-24T10:37:27.006148Z","shell.execute_reply.started":"2024-10-24T10:37:26.610136Z","shell.execute_reply":"2024-10-24T10:37:27.005217Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total no. of lines:  30588\nTotal unique words:  17877\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Mapping from words to integers and vice versa\nstoi={s:i for i,s in enumerate(words)}\nitos={i:s for s,i in stoi.items()}\nprint(len(itos))","metadata":{"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-10-24T10:37:27.007187Z","iopub.execute_input":"2024-10-24T10:37:27.007537Z","iopub.status.idle":"2024-10-24T10:37:27.018874Z","shell.execute_reply.started":"2024-10-24T10:37:27.007504Z","shell.execute_reply":"2024-10-24T10:37:27.017903Z"},"trusted":true},"outputs":[{"name":"stdout","text":"17877\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Generating the labelled dataset","metadata":{}},{"cell_type":"code","source":"# Hyperparameter\nblock_size=5 # context_length: how many words do we take to predict the next one\n\n# X and Y matrices to store the data for training\n# X stores the half lines\n# Y stores the next word\nX,Y=[],[]\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor l in lines:\n  context=[0]*block_size\n  word_l=l.split()\n\n  for i in range(len(word_l)):\n    ix=stoi[word_l[i]]\n    X.append(context)\n    Y.append(ix)\n    # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n    context = context[1:] + [ix]\n\n    if (i==len(word_l)-1):\n        ix=stoi['.']\n        X.append(context)\n        Y.append(ix)\n        # print(' '.join(itos[i] for i in context), '--->', itos[ix])\n        context = context[1:] + [ix]\n\n# Move data to GPU\n\nX = torch.tensor(X).to(device)\nY = torch.tensor(Y).to(device)\n\n\nX.shape, Y.shape, X.dtype, Y.dtype","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-24T10:37:27.020012Z","iopub.execute_input":"2024-10-24T10:37:27.020301Z","iopub.status.idle":"2024-10-24T10:37:30.204999Z","shell.execute_reply.started":"2024-10-24T10:37:27.020270Z","shell.execute_reply":"2024-10-24T10:37:30.203986Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(torch.Size([592621, 5]), torch.Size([592621]), torch.int64, torch.int64)"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Defining the model","metadata":{}},{"cell_type":"code","source":"emb_dim = 64 # Hyperparameter\n\n# Embedding layer\nemb=torch.nn.Embedding(len(stoi),emb_dim).to(device)\nprint(emb)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-24T10:37:30.206389Z","iopub.execute_input":"2024-10-24T10:37:30.206803Z","iopub.status.idle":"2024-10-24T10:37:30.238066Z","shell.execute_reply.started":"2024-10-24T10:37:30.206759Z","shell.execute_reply":"2024-10-24T10:37:30.237211Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Embedding(17877, 64)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class Next_Word_Predictor(nn.Module):\n    def __init__(self, block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value):\n        super().__init__()\n        self.block_size = block_size\n        self.hyperparams = {'block_size':self.block_size, 'emb_dim':emb_dim, 'hidden_dim':hidden_dim, 'activation_fn':activation_fn, 'seed_value':seed_value}\n        self.emb = nn.Embedding(vocab_size, emb_dim)\n        self.linear1 = nn.Linear(block_size * emb_dim, hidden_dim)\n        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n         \n        if activation_fn == 'sigmoid':\n            self.activation = torch.sigmoid  \n        else:\n            self.activation = torch.relu \n\n    def forward(self, x):\n        # Embedding layer\n        x = self.emb(x)\n        x = x.view(x.shape[0], -1)  \n        \n        # Hidden layer\n        x = self.linear1(x)\n        x = self.activation(x)\n        \n        # Output layer\n        x = self.linear2(x)\n        \n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:30.239136Z","iopub.execute_input":"2024-10-24T10:37:30.239704Z","iopub.status.idle":"2024-10-24T10:37:30.247631Z","shell.execute_reply.started":"2024-10-24T10:37:30.239670Z","shell.execute_reply":"2024-10-24T10:37:30.246699Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"def train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device, batch_size=1024, epochs=101, print_every=10):\n    \"\"\"\n    Train the model with the specified seed value.\n    \n    Arguments:\n    X -- training data (input features)\n    Y -- training data (labels)\n    block_size -- context size for input sequence\n    emb_dim -- embedding dimension for the model\n    vocab_size -- the size of the vocabulary\n    hidden_dim -- the size of the hidden layer\n    activation_fn -- the activation function to use ('relu', 'tanh', 'sigmoid')\n    seed_value -- the seed value for reproducibility\n    device -- device to run the training on ('cpu' or 'cuda')\n    batch_size -- the size of each mini-batch (default: 1024)\n    epochs -- number of training epochs (default: 2000)\n    print_every -- print loss after every 'n' epochs (default: 10)\n    \"\"\"\n    \n    torch.manual_seed(seed_value)\n\n    model = Next_Word_Predictor(block_size, vocab_size, emb_dim, hidden_dim, activation_fn, seed_value).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    opt = torch.optim.AdamW(model.parameters(), lr=0.001)\n\n    for epoch in range(epochs):\n        \n        # Mini-batch training\n        for i in range(0, X.shape[0], batch_size):\n            x = X[i:i + batch_size].to(device)\n            y = Y[i:i + batch_size].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n            \n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n        \n        if epoch % print_every == 0:\n            print(f'Epoch {epoch}: Loss = {loss.item()}')\n    \n    return model\n","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-10-24T10:37:30.250536Z","iopub.execute_input":"2024-10-24T10:37:30.250826Z","iopub.status.idle":"2024-10-24T10:37:30.265089Z","shell.execute_reply.started":"2024-10-24T10:37:30.250795Z","shell.execute_reply":"2024-10-24T10:37:30.264284Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"vocab_size = len(stoi)\n# Some other hyperparameters\nhidden_dim = 1024\nactivation_fn = 'relu' \nseed_value = 42 ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:30.266266Z","iopub.execute_input":"2024-10-24T10:37:30.266623Z","iopub.status.idle":"2024-10-24T10:37:30.279164Z","shell.execute_reply.started":"2024-10-24T10:37:30.266574Z","shell.execute_reply":"2024-10-24T10:37:30.278392Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model = train_model(X, Y, block_size, emb_dim, vocab_size, hidden_dim, activation_fn, seed_value, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:37:30.280102Z","iopub.execute_input":"2024-10-24T10:37:30.280397Z","iopub.status.idle":"2024-10-24T11:12:18.688048Z","shell.execute_reply.started":"2024-10-24T10:37:30.280353Z","shell.execute_reply":"2024-10-24T11:12:18.687023Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 6.129698753356934\nEpoch 10: Loss = 1.634093999862671\nEpoch 20: Loss = 1.0681366920471191\nEpoch 30: Loss = 0.797231912612915\nEpoch 40: Loss = 0.650911271572113\nEpoch 50: Loss = 0.5625903010368347\nEpoch 60: Loss = 0.4991651773452759\nEpoch 70: Loss = 0.4519367218017578\nEpoch 80: Loss = 0.42472612857818604\nEpoch 90: Loss = 0.39788398146629333\nEpoch 100: Loss = 0.3888603150844574\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Saving the model\n\ntorch.save(model, 'model_variant_1.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:12:18.689338Z","iopub.execute_input":"2024-10-24T11:12:18.690000Z","iopub.status.idle":"2024-10-24T11:12:18.849686Z","shell.execute_reply.started":"2024-10-24T11:12:18.689965Z","shell.execute_reply":"2024-10-24T11:12:18.848906Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Generating Predictions","metadata":{}},{"cell_type":"code","source":"# Generate names from trained model\n\ndef generate_next_words(model, itos, stoi, content, seed_value, k, max_len=10):\n    torch.manual_seed(seed_value)\n    \n    block_size = model.block_size\n    context = content.lower()\n    context = re.sub('[^a-zA-Z0-9 \\.]', '', context)\n    context = re.sub('\\.', ' . ', context)\n    word_c = context.split()\n    context = []\n    for i in range(len(word_c)):\n        try:\n            if stoi[word_c[i]]:\n                context.append(word_c[i])\n        except:\n            continue\n            \n    context = [stoi[w] for w in context]\n               \n    if len(context) <= block_size:\n        context = [0] * (block_size - len(context)) + context\n    elif len(context) > block_size:\n        context = context[-block_size:]\n\n    for i in range(k):\n        x = torch.tensor(context).view(1, -1).to(device)\n        y_pred = model(x)\n        logits = y_pred\n        \n        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n        word = itos[ix]\n        content += \" \" + word\n        context = context [1:] + [ix]\n        \n    return content\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:12:18.850777Z","iopub.execute_input":"2024-10-24T11:12:18.851079Z","iopub.status.idle":"2024-10-24T11:12:18.860963Z","shell.execute_reply.started":"2024-10-24T11:12:18.851047Z","shell.execute_reply":"2024-10-24T11:12:18.859912Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Generate names from trained model\n\npara=\"\"\ncontent=input(\"Enter some content: \")\nk=int(input(\"Enter no. of words to be generated: \"))\npara+=generate_next_words(model, itos, stoi, content, seed_value, k)\npara+=\"\\n\\n\"\nprint(para)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:14:50.468182Z","iopub.execute_input":"2024-10-24T11:14:50.468575Z","iopub.status.idle":"2024-10-24T11:14:55.359702Z","shell.execute_reply.started":"2024-10-24T11:14:50.468536Z","shell.execute_reply":"2024-10-24T11:14:55.358753Z"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter some content:  she continued after a short pause, drawing nearer to the prince and smiling amiably at him as if to show that political and social topics were ended\nEnter no. of words to be generated:  40\n"},{"name":"stdout","text":"she continued after a short pause, drawing nearer to the prince and smiling amiably at him as if to show that political and social topics were ended and the time had come for the old war the countess did in her words nicholas expressed a power to be set off . in the house was always anxious or i will only to recalled the activity of the\n\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Visualization of embeddings","metadata":{}},{"cell_type":"code","source":"embedding_weights = model.emb.weight.detach().cpu().numpy() #to be used for visualization","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:15:49.803712Z","iopub.execute_input":"2024-10-24T11:15:49.804466Z","iopub.status.idle":"2024-10-24T11:15:49.810423Z","shell.execute_reply.started":"2024-10-24T11:15:49.804424Z","shell.execute_reply":"2024-10-24T11:15:49.809422Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\n# Set the number of clusters (you can experiment with this number)\nn_clusters = 10\n\n# Perform K-means clustering on the embeddings\nkmeans = KMeans(n_clusters=n_clusters, random_state=1)\nclusters = kmeans.fit_predict(embedding_weights)\n\n# Create a dictionary to store words grouped by cluster\nclustered_words = {i: [] for i in range(n_clusters)}\n\n# Assign words to their respective clusters\nfor word, idx in stoi.items():\n    if idx < embedding_weights.shape[0]:\n        cluster = clusters[idx]\n        clustered_words[cluster].append(word)\n\n# Print words in each cluster\nfor cluster, words in clustered_words.items():\n    print(f\"Cluster {cluster}: {', '.join(words[:10])}\")  # Limiting to first 10 words for readability","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:13:52.682578Z","iopub.execute_input":"2024-10-24T11:13:52.682934Z","iopub.status.idle":"2024-10-24T11:13:56.974455Z","shell.execute_reply.started":"2024-10-24T11:13:52.682893Z","shell.execute_reply":"2024-10-24T11:13:56.973455Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Cluster 0: prettier, fwiend, deplorable, recite, fabviers, supposition, bosse, growled, assert, lha\nCluster 1: listener, gunner, witnessed, shorter, steshka, upwards, yawned, vue, gratitude, arrive\nCluster 2: shadow, collect, bothering, deck, typically, chanting, antique, childish, deceitful, effectively\nCluster 3: admirable, drain, tilted, load, diagnosed, fists, maps, stuffed, advice, earliest\nCluster 4: mortiers, perceive, twigs, anticipate, rounded, genius, foliage, melyukovka, recommendation, joined\nCluster 5: ville, cloaks, withdrew, dragoon, energique, watching, retreats, impedes, call, prize\nCluster 6: crumpling, honors, difficult, furiously, decorating, selection, discard, accentuating, fluff, prettily\nCluster 7: ascended, interceded, startling, corporal, drop, infinitesimals, grabern, didnt, hillside, batiste\nCluster 8: dismounting, rotted, influences, appointments, enriched, ignorance, enforce, experts, disquiet, cartload\nCluster 9: adam, workingman, godson, loyalty, complacently, dreary, cord, threadbare, imprudent, antonovna\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"embedding_weights = model.emb.weight.detach().cpu().numpy() #to be used for visualization\nprint(embedding_weights.shape)\n# Reduce dimensionality using t-SNE\ntsne = TSNE(n_components=2, random_state=1)\nembeddings_tsne = tsne.fit_transform(embedding_weights)\n\n# Visualize embeddings\nplt.figure(figsize=(10, 8))\nplt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], alpha=0.5)\nplt.title('t-SNE Visualization of Embeddings')  \nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:13:56.975787Z","iopub.execute_input":"2024-10-24T11:13:56.976499Z","iopub.status.idle":"2024-10-24T11:13:57.886886Z","shell.execute_reply.started":"2024-10-24T11:13:56.976452Z","shell.execute_reply":"2024-10-24T11:13:57.885611Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(17877, 64)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedding_weights\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Reduce dimensionality using t-SNE\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tsne \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m embeddings_tsne \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(embedding_weights)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Visualize embeddings\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'TSNE' is not defined"],"ename":"NameError","evalue":"name 'TSNE' is not defined","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"texxt = \"My name is Soham....\"\nfiltered_text = re.sub(r'-', ' ', texxt)\nfiltered_text = re.sub('[^a-zA-Z0-9 \\.\\n]', '', filtered_text)\nfiltered_text = re.sub(r'\\..', '', filtered_text)\nfiltered_text = filtered_text.lower()\nprint(filtered_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T11:13:57.888175Z","iopub.status.idle":"2024-10-24T11:13:57.888700Z","shell.execute_reply.started":"2024-10-24T11:13:57.888434Z","shell.execute_reply":"2024-10-24T11:13:57.888462Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### ","metadata":{}}]}